#!/usr/bin/env python3
"""
å›½åœŸæ•°å€¤æƒ…å ±ï¼ˆåœ°ä¾¡å…¬ç¤ºï¼‰Shapefile/GeoJSON â†’ PostgreSQL ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

2000-2025å¹´ã®26å¹´åˆ†ã®å›½åœŸæ•°å€¤æƒ…å ±ï¼ˆåœ°ä¾¡å…¬ç¤ºï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’
PostgreSQLã®land_pricesãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚

Usage:
    python scripts/20_import_historical_kokudo_data.py                    # å…¨å¹´åº¦å‡¦ç†
    python scripts/20_import_historical_kokudo_data.py --year 2000       # å˜å¹´åº¦å‡¦ç†
    python scripts/20_import_historical_kokudo_data.py --start 2018 --end 2025  # ç¯„å›²æŒ‡å®š
"""

import geopandas as gpd
import pandas as pd
import psycopg2
from pathlib import Path
from tqdm import tqdm
import os
import sys
import re
import logging
import argparse
from typing import Optional, Tuple, List
from dotenv import load_dotenv
import yaml

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/real_estate_bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def load_db_config():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
    config_path = project_root / 'config' / 'database.yml'
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return {
        'host': os.getenv('DB_HOST', config['postgresql'].get('host', 'localhost')),
        'port': int(os.getenv('DB_PORT', config['postgresql'].get('port', 5432))),
        'database': os.getenv('DB_NAME', config['postgresql'].get('database', 'real_estate_dev')),
        'user': os.getenv('DB_USER', config['postgresql'].get('user', 'postgres')),
        'password': os.getenv('DB_PASSWORD', config['postgresql'].get('password', 'postgres'))
    }


def get_file_path(year: int) -> Optional[str]:
    """
    å¹´åº¦ã«å¿œã˜ã¦æ­£ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™
    
    Args:
        year: èª¿æŸ»å¹´ï¼ˆ2000-2025ï¼‰
    
    Returns:
        str: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆ.shp ã¾ãŸã¯ .geojsonï¼‰ã€å­˜åœ¨ã—ãªã„å ´åˆã¯None
    
    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    base_dir = project_root / 'data' / 'raw' / 'national' / 'kokudo_suuchi'
    year_dir = base_dir / f"{year}_13"
    
    if not year_dir.exists():
        return None
    
    yy = str(year)[-2:]  # ä¸‹2æ¡ï¼ˆä¾‹: 2000 -> "00"ï¼‰
    
    # 2018å¹´ä»¥é™: GeoJSONã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
    if year >= 2018:
        # GMLãƒ•ã‚©ãƒ«ãƒ€å†…ã®GeoJSONã‚’å„ªå…ˆ
        gml_dir = year_dir / f"L01-{yy}_13_GML"
        if gml_dir.exists():
            geojson_path = gml_dir / f"L01-{yy}_13.geojson"
            if geojson_path.exists():
                return str(geojson_path)
        
        # ç›´æ¥GeoJSONï¼ˆGMLãƒ•ã‚©ãƒ«ãƒ€ãªã—ã€ä¾‹: 2022å¹´ï¼‰
        geojson_path = year_dir / f"L01-{yy}_13.geojson"
        if geojson_path.exists():
            return str(geojson_path)
        
        # GMLãƒ•ã‚©ãƒ«ãƒ€å†…ã®Shapefileï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if gml_dir.exists():
            shp_path = gml_dir / f"L01-{yy}_13.shp"
            if shp_path.exists():
                return str(shp_path)
        
        # ç›´æ¥Shapefileï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        shp_path = year_dir / f"L01-{yy}_13.shp"
        if shp_path.exists():
            return str(shp_path)
    
    # 2015-2017å¹´: GMLãƒ•ã‚©ãƒ«ãƒ€å†…ã®Shapefileã¾ãŸã¯ç›´æ¥Shapefile
    elif year >= 2015:
        # 2015å¹´ã¯GMLãƒ•ã‚©ãƒ«ãƒ€å†…
        if year == 2015:
            gml_dir = year_dir / f"L01-{yy}_13_GML"
            if gml_dir.exists():
                shp_path = gml_dir / f"L01-{yy}_13.shp"
                if shp_path.exists():
                    return str(shp_path)
        else:
            # 2016-2017å¹´ã¯ç›´æ¥Shapefile
            shp_path = year_dir / f"L01-{yy}_13.shp"
            if shp_path.exists():
                return str(shp_path)
    
    # 2012-2014å¹´: ä¸­é–“å½¢å¼ï¼ˆç›´æ¥Shapefileï¼‰
    elif year >= 2012:
        shp_path = year_dir / f"L01-{yy}_13.shp"
        if shp_path.exists():
            return str(shp_path)
    
    # 2000-2011å¹´: å¤ã„å½¢å¼ï¼ˆ-g_LandPrice.shpï¼‰
    else:
        shp_path = year_dir / f"L01-{yy}_13-g_LandPrice.shp"
        if shp_path.exists():
            return str(shp_path)
    
    return None


def load_land_price_data(year: int, debug: bool = False) -> Optional[gpd.GeoDataFrame]:
    """
    ä»»æ„ã®å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€å½¢å¼ã§èª­ã¿è¾¼ã‚€
    
    Args:
        year: èª¿æŸ»å¹´ï¼ˆ2000-2025ï¼‰
    
    Returns:
        GeoDataFrame: åœ°ä¾¡ãƒ‡ãƒ¼ã‚¿ + ã‚¸ã‚ªãƒ¡ãƒˆãƒªã€èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯None
    """
    file_path = get_file_path(year)
    
    if file_path is None:
        logger.warning(f"âš ï¸ {year}å¹´ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    if not Path(file_path).exists():
        logger.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")
        return None
    
    try:
        logger.info(f"[{year}å¹´] ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {file_path}")
        gdf = gpd.read_file(file_path)
        logger.info(f"[{year}å¹´] ç·ä»¶æ•°: {len(gdf)} åœ°ç‚¹")
        
        # ãƒ‡ãƒãƒƒã‚°: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ç›´å¾Œã®è©³ç´°å‡ºåŠ›
        if debug:
            print("\n" + "=" * 60)
            print(f"=== ãƒ‡ãƒãƒƒã‚°: [{year}å¹´] èª­ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ ===")
            print(f"åˆ—åï¼ˆæœ€åˆã®30å€‹ï¼‰: {gdf.columns.tolist()[:30]}")
            print(f"ç·åˆ—æ•°: {len(gdf.columns)}")
            print(f"ç·ä»¶æ•°: {len(gdf)}")
            
            # å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ã®ç¢ºèª
            for col_name in ['L01_001', 'L01_017', 'L01_021']:
                if col_name in gdf.columns:
                    print(f"\n{col_name}ï¼ˆå¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰å€™è£œï¼‰:")
                    sample_values = gdf[col_name].head(10).tolist()
                    print(f"  ã‚µãƒ³ãƒ—ãƒ«å€¤: {sample_values}")
                    
                    # ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã®ç¢ºèª
                    unique_values = gdf[col_name].unique()[:20]
                    print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ï¼ˆæœ€åˆã®20å€‹ï¼‰: {unique_values.tolist()}")
                    
                    # ä¸–ç”°è°·åŒºé–¢é€£ã®å€¤ã‚’ç¢ºèª
                    if hasattr(gdf[col_name], 'astype'):
                        str_values = gdf[col_name].astype(str)
                        setagaya_count = str_values.str.contains('13112|13', na=False).sum()
                        print(f"  '13'ã‚’å«ã‚€å€¤ã®ä»¶æ•°: {setagaya_count}")
            
            # ä½æ‰€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
            for col_name in ['L01_019', 'L01_023', 'L01_024', 'L01_025']:
                if col_name in gdf.columns:
                    print(f"\n{col_name}ï¼ˆä½æ‰€å€™è£œï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«:")
                    for i, addr in enumerate(gdf[col_name].head(5), 1):
                        if pd.notna(addr):
                            print(f"  {i}. {str(addr)[:80]}")
        
        # ä¸–ç”°è°·åŒºã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰: 13112ï¼‰
        # L01_017ãŒå¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ï¼ˆå¹´åº¦ã«ã‚ˆã£ã¦ä½ç½®ãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™ï¼‰
        city_code_col = None
        
        # ã¾ãšã€å„å€™è£œåˆ—ã§ä¸–ç”°è°·åŒºï¼ˆ13112ï¼‰ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        for col in ['L01_017', 'L01_001', 'L01_021']:
            if col in gdf.columns:
                # æ–‡å­—åˆ—å‹ã¨ã—ã¦ãƒã‚§ãƒƒã‚¯
                str_values = gdf[col].astype(str)
                has_setagaya = (str_values == '13112').any() or (str_values.str.startswith('13112', na=False)).any()
                
                # æ•°å€¤å‹ã¨ã—ã¦ã‚‚ãƒã‚§ãƒƒã‚¯
                if not has_setagaya:
                    try:
                        num_values = pd.to_numeric(gdf[col], errors='coerce')
                        has_setagaya = (num_values == 13112).any()
                    except:
                        pass
                
                if has_setagaya:
                    city_code_col = col
                    if debug:
                        print(f"âœ… å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰åˆ—ã¨ã—ã¦ '{col}' ã‚’ä½¿ç”¨")
                    break
        
        if city_code_col:
            # ä¸–ç”°è°·åŒºï¼ˆ13112ï¼‰ã§ãƒ•ã‚£ãƒ«ã‚¿
            setagaya_gdf = None
            
            # æ•°å€¤å‹ã¨ã—ã¦å‡¦ç†ï¼ˆ13112 = ä¸–ç”°è°·åŒºï¼‰
            try:
                num_values = pd.to_numeric(gdf[city_code_col], errors='coerce')
                setagaya_gdf = gdf[num_values == 13112]
            except:
                pass
            
            # æ–‡å­—åˆ—ã¨ã—ã¦å‡¦ç†ï¼ˆ13112ã¾ãŸã¯"13112"ã§å§‹ã¾ã‚‹ï¼‰
            if setagaya_gdf is None or len(setagaya_gdf) == 0:
                try:
                    str_values = gdf[city_code_col].astype(str)
                    # å®Œå…¨ä¸€è‡´ã¾ãŸã¯å‰æ–¹ä¸€è‡´
                    setagaya_gdf = gdf[str_values.str.startswith('13112', na=False)]
                except:
                    pass
            
            # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€'13'ã§å§‹ã¾ã‚‹ã‚‚ã®ã‚’è©¦ã™ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            if (setagaya_gdf is None or len(setagaya_gdf) == 0) and debug:
                try:
                    str_values = gdf[city_code_col].astype(str)
                    all_13 = gdf[str_values.str.startswith('13', na=False)]
                    print(f"\nâš ï¸ ä¸–ç”°è°·åŒºï¼ˆ13112ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚'13'ã§å§‹ã¾ã‚‹ãƒ‡ãƒ¼ã‚¿: {len(all_13)}ä»¶")
                    if len(all_13) > 0:
                        unique_codes = all_13[city_code_col].unique()[:10]
                        print(f"  å«ã¾ã‚Œã‚‹å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰: {unique_codes.tolist()}")
                except:
                    pass
            
            if debug and city_code_col:
                print(f"\nä½¿ç”¨ã—ãŸãƒ•ã‚£ãƒ«ã‚¿åˆ—: {city_code_col}")
                if setagaya_gdf is not None and len(setagaya_gdf) > 0:
                    print(f"ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰åˆ†å¸ƒ:")
                    code_counts = setagaya_gdf[city_code_col].value_counts().head(10)
                    for code, count in code_counts.items():
                        print(f"  {code}: {count}ä»¶")
        else:
            # å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ã§çµã‚Œãªã„å ´åˆã¯ã€å¸‚åŒºç”ºæ‘åã§çµã‚‹
            city_name_cols = ['L01_018', 'L01_019', 'L01_022', 'L01_023', 'L01_024']
            setagaya_gdf = None
            used_col = None
            for col in city_name_cols:
                if col in gdf.columns:
                    gdf[col] = gdf[col].astype(str)
                    if 'ä¸–ç”°è°·' in gdf[col].values:
                        setagaya_gdf = gdf[gdf[col].str.contains('ä¸–ç”°è°·', na=False)]
                        used_col = col
                        break
            
            if setagaya_gdf is None:
                logger.warning(f"[{year}å¹´] ä¸–ç”°è°·åŒºã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                if debug:
                    print(f"\nâš ï¸ ä¸–ç”°è°·åŒºã®ãƒ•ã‚£ãƒ«ã‚¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
            
            if debug:
                print(f"\nä½¿ç”¨ã—ãŸãƒ•ã‚£ãƒ«ã‚¿åˆ—ï¼ˆå¸‚åŒºç”ºæ‘åï¼‰: {used_col}")
        
        logger.info(f"[{year}å¹´] ä¸–ç”°è°·åŒºãƒ•ã‚£ãƒ«ã‚¿: {len(setagaya_gdf)} åœ°ç‚¹")
        
        # ãƒ‡ãƒãƒƒã‚°: ä¸–ç”°è°·åŒºãƒ•ã‚£ãƒ«ã‚¿å¾Œã®è©³ç´°å‡ºåŠ›
        if debug:
            print(f"\n=== ãƒ‡ãƒãƒƒã‚°: [{year}å¹´] ä¸–ç”°è°·åŒºãƒ•ã‚£ãƒ«ã‚¿å¾Œ ===")
            print(f"ãƒ•ã‚£ãƒ«ã‚¿å¾Œä»¶æ•°: {len(setagaya_gdf)}")
            
            if len(setagaya_gdf) > 0:
                # ä½æ‰€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¢ã™
                address_field = None
                for col in ['L01_019', 'L01_023', 'L01_024', 'L01_025']:
                    if col in setagaya_gdf.columns:
                        address_field = col
                        break
                
                if address_field:
                    print(f"\nä½æ‰€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {address_field}")
                    print(f"ä½æ‰€ã‚µãƒ³ãƒ—ãƒ«ï¼ˆãƒ•ã‚£ãƒ«ã‚¿å¾Œï¼‰:")
                    for i, addr in enumerate(setagaya_gdf[address_field].head(5), 1):
                        if pd.notna(addr):
                            print(f"  {i}. {str(addr)[:80]}")
        
        return setagaya_gdf
    
    except Exception as e:
        logger.error(f"[{year}å¹´] ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None


def extract_choume_name(address: str) -> Optional[str]:
    """
    æ‰€åœ¨åœ°ã‹ã‚‰ç”ºä¸ç›®åã‚’æŠ½å‡ºï¼ˆæ­£è¦åŒ–ç‰ˆã€ä¸ç›®ä»˜ãã§è¿”ã™ï¼‰
    
    ä¾‹: "æ±äº¬éƒ½ã€€ä¸–ç”°è°·åŒºä¸ŠåŒ—æ²¢ï¼“ä¸ç›®ï¼’ï¼•ç•ªï¼‘ï¼" â†’ "ä¸ŠåŒ—æ²¢3ä¸ç›®"
        "æ¡œä¸Šæ°´ï¼•âˆ’ï¼”ï¼âˆ’ï¼‘ï¼" â†’ "æ¡œä¸Šæ°´5ä¸ç›®"
    
    Args:
        address: æ‰€åœ¨åœ°ä½æ‰€
    
    Returns:
        str: ç”ºä¸ç›®åï¼ˆä¾‹: "ä¸ŠåŒ—æ²¢3ä¸ç›®"ï¼‰ã€æŠ½å‡ºå¤±æ•—æ™‚ã¯None
    """
    if not address or not isinstance(address, str):
        return None
    
    # å…¨è§’æ•°å­—ã‚’åŠè§’ã«å¤‰æ›
    address = address.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
    
    # å…¨è§’ãƒã‚¤ãƒ•ãƒ³ã‚’åŠè§’ã«
    address = address.replace('âˆ’', '-').replace('ãƒ¼', '-')
    
    # "ä¸–ç”°è°·åŒº"ä»¥é™ã‚’æŠ½å‡º
    if 'ä¸–ç”°è°·åŒº' in address:
        address = address.split('ä¸–ç”°è°·åŒº')[1]
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: "â—¯â—¯Nä¸ç›®" ã®å½¢å¼ï¼ˆã™ã§ã«ä¸ç›®ãŒã‚ã‚‹ï¼‰
    # ä¾‹: "ç­‰ã€…åŠ›5ä¸ç›®ï¼“ï¼“ç•ªï¼‘ï¼•" â†’ "ç­‰ã€…åŠ›5ä¸ç›®"
    pattern1 = r'^(.+?)(\d+)ä¸ç›®'
    match = re.search(pattern1, address)
    if match:
        area_name = match.group(1).strip()
        choume_num = match.group(2)
        return f"{area_name}{choume_num}ä¸ç›®"
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: "â—¯â—¯N-" ã®å½¢å¼ï¼ˆä¸ç›®ãŒãªã„ï¼‰
    # ä¾‹: "æ¡œä¸Šæ°´5-ï¼”ï¼-ï¼‘ï¼" â†’ "æ¡œä¸Šæ°´5ä¸ç›®"
    pattern2 = r'^(.+?)(\d+)[-âˆ’ãƒ¼]'
    match = re.search(pattern2, address)
    if match:
        area_name = match.group(1).strip()
        choume_num = match.group(2)
        return f"{area_name}{choume_num}ä¸ç›®"
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: "â—¯â—¯Nç•ª" ã®å½¢å¼
    # ä¾‹: "ä¸Šé¦¬17ç•ªï¼‘ï¼’" â†’ "ä¸Šé¦¬1ä¸ç›®"ï¼ˆæœ€åˆã®æ•°å­—ã‚’ä¸ç›®ã¨ã—ã¦æ‰±ã†ï¼‰
    pattern3 = r'^(.+?)(\d+)ç•ª'
    match = re.search(pattern3, address)
    if match:
        area_name = match.group(1).strip()
        choume_num = match.group(2)
        # æœ€åˆã®æ•°å­—ã‚’ä¸ç›®ã¨ã—ã¦æ‰±ã†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if choume_num:
            return f"{area_name}{choume_num[0]}ä¸ç›®"
    
    return None


def match_with_choume(gdf: gpd.GeoDataFrame, conn, year: int, debug: bool = False) -> pd.DataFrame:
    """
    å›½åœŸæ•°å€¤æƒ…å ±ã®ä½æ‰€ã‚’choumeãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãƒãƒƒãƒãƒ³ã‚°
    
    Args:
        gdf: GeoDataFrameï¼ˆå›½åœŸæ•°å€¤æƒ…å ±ï¼‰
        conn: PostgreSQLæ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        year: èª¿æŸ»å¹´
    
    Returns:
        DataFrame: choume_codeä»˜ããƒ‡ãƒ¼ã‚¿
    """
    cursor = conn.cursor()
    
    # ãƒ‡ãƒãƒƒã‚°: choumeãƒ†ãƒ¼ãƒ–ãƒ«ã®æ§‹é€ ã‚’ç¢ºèª
    if debug:
        print("\n" + "=" * 60)
        print(f"=== ãƒ‡ãƒãƒƒã‚°: [{year}å¹´] ç”ºä¸ç›®ãƒã‚¹ã‚¿å–å¾—å‰ ===")
        cursor.execute("SELECT COUNT(*) FROM choume")
        total_choume_count = cursor.fetchone()[0]
        print(f"å…¨choumeãƒ†ãƒ¼ãƒ–ãƒ«ã®ä»¶æ•°: {total_choume_count}")
        
        # city_codeã®åˆ†å¸ƒã‚’ç¢ºèª
        cursor.execute("""
            SELECT city_code, COUNT(*) as cnt
            FROM choume
            GROUP BY city_code
            ORDER BY cnt DESC
            LIMIT 10
        """)
        city_code_dist = cursor.fetchall()
        print(f"\ncity_codeã®åˆ†å¸ƒï¼ˆä¸Šä½10ä»¶ï¼‰:")
        for city_code, cnt in city_code_dist:
            print(f"  {city_code}: {cnt}ä»¶")
        
        # ä¸–ç”°è°·åŒºï¼ˆ13112ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
        cursor.execute("""
            SELECT COUNT(*) 
            FROM choume 
            WHERE city_code = '13112'
        """)
        setagaya_count = cursor.fetchone()[0]
        print(f"\nä¸–ç”°è°·åŒºï¼ˆcity_code='13112'ï¼‰ã®ä»¶æ•°: {setagaya_count}")
        
        cursor.execute("""
            SELECT COUNT(*) 
            FROM choume 
            WHERE city_code LIKE '13%'
        """)
        tokyo_ku_count = cursor.fetchone()[0]
        print(f"æ±äº¬éƒ½ã®åŒºï¼ˆcity_code LIKE '13%'ï¼‰ã®ä»¶æ•°: {tokyo_ku_count}")
    
    # ç”ºä¸ç›®ãƒã‚¹ã‚¿ã‚’å–å¾—ï¼ˆä¸–ç”°è°·åŒºã®ã¿ï¼‰
    # city_codeã¯VARCHARå‹ãªã®ã§æ–‡å­—åˆ—ã§æ¯”è¼ƒ
    cursor.execute("""
        SELECT choume_code, choume_name, city_code
        FROM choume
        WHERE city_code = '13112' OR city_code LIKE '13112%'
        ORDER BY choume_code
    """)
    choume_records = cursor.fetchall()
    choume_dict = {row[1]: row[0] for row in choume_records}  # name -> code ãƒãƒƒãƒ”ãƒ³ã‚°
    
    logger.info(f"[{year}å¹´] ç”ºä¸ç›®ãƒã‚¹ã‚¿: {len(choume_dict)} ä»¶")
    
    # ãƒ‡ãƒãƒƒã‚°: ç”ºä¸ç›®ãƒã‚¹ã‚¿å–å¾—å¾Œã®è©³ç´°å‡ºåŠ›
    if debug:
        print(f"\n=== ãƒ‡ãƒãƒƒã‚°: [{year}å¹´] ç”ºä¸ç›®ãƒã‚¹ã‚¿å–å¾—å¾Œ ===")
        print(f"å–å¾—ä»¶æ•°: {len(choume_dict)} ä»¶")
        
        if len(choume_dict) > 0:
            print(f"\nç”ºä¸ç›®ãƒã‚¹ã‚¿ï¼ˆæœ€åˆã®20ä»¶ï¼‰:")
            for i, (name, code) in enumerate(list(choume_dict.items())[:20], 1):
                print(f"  {i:2d}. {name:20s} -> {code}")
        else:
            print("âš ï¸ ç”ºä¸ç›®ãƒã‚¹ã‚¿ãŒç©ºã§ã™ï¼")
            
            # choumeãƒ†ãƒ¼ãƒ–ãƒ«ã®å†…å®¹ã‚’ç¢ºèª
            cursor.execute("SELECT COUNT(*) FROM choume")
            total_count = cursor.fetchone()[0]
            print(f"\nå…¨choumeãƒ†ãƒ¼ãƒ–ãƒ«ã®ä»¶æ•°: {total_count}")
            
            if total_count > 0:
                cursor.execute("""
                    SELECT choume_code, choume_name, city_code
                    FROM choume
                    ORDER BY city_code, choume_name
                    LIMIT 20
                """)
                print(f"\nå…¨choumeãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®20ä»¶ï¼‰:")
                for row in cursor.fetchall():
                    print(f"  {row[2]:8s} | {row[1]:20s} | {row[0]}")
                
                # city_codeã®åˆ†å¸ƒã‚’ç¢ºèª
                cursor.execute("""
                    SELECT city_code, COUNT(*) as cnt
                    FROM choume
                    GROUP BY city_code
                    ORDER BY cnt DESC
                    LIMIT 10
                """)
                print(f"\ncity_codeã®åˆ†å¸ƒ:")
                for city_code, cnt in cursor.fetchall():
                    print(f"  {city_code}: {cnt}ä»¶")
                
                # ä¸–ç”°è°·åŒºï¼ˆ13112ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥ç¢ºèª
                cursor.execute("""
                    SELECT choume_code, choume_name
                    FROM choume
                    WHERE city_code = '13112'
                    ORDER BY choume_name
                    LIMIT 10
                """)
                setagaya_records = cursor.fetchall()
                if setagaya_records:
                    print(f"\nä¸–ç”°è°·åŒºï¼ˆcity_code='13112'ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆã®10ä»¶ï¼‰:")
                    for code, name in setagaya_records:
                        print(f"  {code} | {name}")
                else:
                    print(f"\nâš ï¸ ä¸–ç”°è°·åŒºï¼ˆcity_code='13112'ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            else:
                print("\nâš ï¸ choumeãƒ†ãƒ¼ãƒ–ãƒ«ãŒå®Œå…¨ã«ç©ºã§ã™ã€‚å…ˆã«21_import_choume_master.pyã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    # ä½æ‰€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¢ã™ï¼ˆå¹´åº¦ã«ã‚ˆã£ã¦ç•°ãªã‚‹ï¼‰
    address_col = None
    for col in ['L01_019', 'L01_023', 'L01_024', 'L01_025']:
        if col in gdf.columns:
            address_col = col
            break
    
    if address_col is None:
        logger.error(f"[{year}å¹´] ä½æ‰€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return pd.DataFrame()
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç¢ºèª
    survey_year_col = 'L01_005'
    price_col = 'L01_006'
    city_code_col = None
    city_name_col = None
    land_area_col = None
    
    for col in ['L01_017', 'L01_018', 'L01_021', 'L01_001']:
        if col in gdf.columns:
            city_code_col = col
            break
    
    for col in ['L01_018', 'L01_019', 'L01_022', 'L01_023', 'L01_024']:
        if col in gdf.columns:
            city_name_col = col
            break
    
    for col in ['L01_020', 'L01_024', 'L01_026', 'L01_027']:
        if col in gdf.columns:
            land_area_col = col
            break
    
    matched_records = []
    skipped_count = 0
    
    # ãƒ‡ãƒãƒƒã‚°: ç”ºä¸ç›®æŠ½å‡ºã®ãƒ†ã‚¹ãƒˆ
    if debug and len(gdf) > 0:
        print(f"\n=== ãƒ‡ãƒãƒƒã‚°: [{year}å¹´] ç”ºä¸ç›®æŠ½å‡ºãƒ»ãƒãƒƒãƒãƒ³ã‚° ===")
        print(f"å‡¦ç†å¯¾è±¡ä»¶æ•°: {len(gdf)} ä»¶")
        print(f"\næœ€åˆã®5ä»¶ã®æŠ½å‡ºçµæœ:")
        
        for i, (idx, row) in enumerate(gdf.head(5).iterrows(), 1):
            address = str(row.get(address_col, ''))
            choume_name_extracted = extract_choume_name(address) if address and address != 'nan' else None
            
            # ãƒãƒƒãƒãƒ³ã‚°è©¦è¡Œ
            matched_code = None
            if choume_name_extracted:
                if choume_name_extracted in choume_dict:
                    matched_code = choume_dict[choume_name_extracted]
                else:
                    # éƒ¨åˆ†ä¸€è‡´ã‚’è©¦ã™
                    normalized_extracted = choume_name_extracted.replace('ä¸ç›®', '').strip()
                    for db_name, db_code in choume_dict.items():
                        normalized_db = db_name.replace('ä¸ç›®', '').strip()
                        if normalized_extracted == normalized_db:
                            matched_code = db_code
                            break
            
            print(f"\n  {i}. å…ƒä½æ‰€: {address[:60] if address else '(ç©º)'}")
            print(f"     æŠ½å‡ºçµæœ: {choume_name_extracted or '(æŠ½å‡ºå¤±æ•—)'}")
            print(f"     ãƒãƒƒãƒã‚³ãƒ¼ãƒ‰: {matched_code or '(ãƒãƒƒãƒãªã—)'}")
            
            if choume_name_extracted and not matched_code:
                # ãƒãƒƒãƒå¤±æ•—æ™‚ã€é¡ä¼¼æ¤œç´¢
                if len(choume_dict) > 0:
                    normalized_extracted = choume_name_extracted.replace('ä¸ç›®', '').strip()
                    similar = []
                    for db_name, db_code in choume_dict.items():
                        normalized_db = db_name.replace('ä¸ç›®', '').strip()
                        # å‰æ–¹ä¸€è‡´ã¾ãŸã¯å¾Œæ–¹ä¸€è‡´ã§é¡ä¼¼ã‚’æ¤œç´¢
                        if normalized_extracted[:2] in normalized_db or normalized_db[:2] in normalized_extracted:
                            similar.append((db_name, db_code))
                        # éƒ¨åˆ†ä¸€è‡´ã‚‚è¿½åŠ 
                        elif normalized_extracted in normalized_db or normalized_db in normalized_extracted:
                            similar.append((db_name, db_code))
                    
                    if similar:
                        print(f"     é¡ä¼¼å€™è£œï¼ˆæœ€åˆã®5ä»¶ï¼‰:")
                        for name, code in similar[:5]:
                            print(f"       - {name} ({code})")
                    else:
                        print(f"     é¡ä¼¼å€™è£œ: ãªã—")
    
    for idx, row in gdf.iterrows():
        address = str(row.get(address_col, ''))
        if not address or address == 'nan':
            skipped_count += 1
            continue
        
        # ç”ºä¸ç›®åã‚’æŠ½å‡º
        choume_name_extracted = extract_choume_name(address)
        if not choume_name_extracted:
            skipped_count += 1
            if skipped_count <= 10:  # æœ€åˆã®10ä»¶ã®ã¿ãƒ­ã‚°å‡ºåŠ›
                logger.debug(f"  âš ï¸ ä½æ‰€æŠ½å‡ºå¤±æ•—: {address[:50]}")
            continue
        
        # ãƒãƒƒãƒãƒ³ã‚°ï¼ˆæŸ”è»Ÿãªæ¤œç´¢ï¼‰
        matched_code = None
        matched_name = None
        
        # å®Œå…¨ä¸€è‡´
        if choume_name_extracted in choume_dict:
            matched_code = choume_dict[choume_name_extracted]
            matched_name = choume_name_extracted
        else:
            # ä¸ç›®ã®æœ‰ç„¡ã‚’æ­£è¦åŒ–ã—ã¦æ¯”è¼ƒ
            normalized_extracted = choume_name_extracted.replace('ä¸ç›®', '').strip()
            
            for db_name, db_code in choume_dict.items():
                normalized_db = db_name.replace('ä¸ç›®', '').strip()
                
                # æ­£è¦åŒ–å¾Œã®å®Œå…¨ä¸€è‡´
                if normalized_extracted == normalized_db:
                    matched_code = db_code
                    matched_name = db_name
                    break
                
                # å‰æ–¹ä¸€è‡´ï¼ˆæŠ½å‡ºåãŒDBåã®å…ˆé ­ã«å«ã¾ã‚Œã‚‹ï¼‰
                if normalized_extracted and normalized_extracted in normalized_db:
                    # ã‚ˆã‚Šå…·ä½“çš„ãªãƒãƒƒãƒã‚’å„ªå…ˆï¼ˆé•·ã„åå‰ã‚’å„ªå…ˆï¼‰
                    if matched_code is None or len(normalized_db) > len(choume_dict.get(matched_code, '').replace('ä¸ç›®', '')):
                        matched_code = db_code
                        matched_name = db_name
                
                # å¾Œæ–¹ä¸€è‡´ï¼ˆDBåãŒæŠ½å‡ºåã®å…ˆé ­ã«å«ã¾ã‚Œã‚‹ï¼‰
                elif normalized_db and normalized_db in normalized_extracted:
                    matched_code = db_code
                    matched_name = db_name
                    break
        
        if not matched_code:
            skipped_count += 1
            if skipped_count <= 10:
                logger.debug(f"  âš ï¸ ãƒãƒƒãƒãªã—: {choume_name_extracted} (å…ƒä½æ‰€: {address[:50]})")
            continue
        
        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        try:
            survey_year = int(row.get(survey_year_col, year))
            price_str = str(row.get(price_col, ''))
            # ç©ºæ–‡å­—ã‚„"_"ã‚’é™¤å»
            price_str = price_str.replace('_', '').strip()
            price_per_sqm = int(price_str) if price_str and price_str.isdigit() else None
            
            if price_per_sqm is None:
                logger.debug(f"  âš ï¸ ä¾¡æ ¼ãŒç„¡åŠ¹: {price_str}")
                skipped_count += 1
                continue
            
            land_area = None
            if land_area_col and land_area_col in row:
                land_area_str = str(row[land_area_col]).replace('_', '').strip()
                try:
                    land_area = float(land_area_str) if land_area_str else None
                except (ValueError, TypeError):
                    pass
            
            # ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‹ã‚‰åº§æ¨™ã‚’å–å¾—
            latitude = None
            longitude = None
            if row.geometry and row.geometry.geom_type == 'Point':
                longitude, latitude = row.geometry.x, row.geometry.y
            elif row.geometry:
                # Polygonã‚„ãã®ä»–ã®ã‚¸ã‚ªãƒ¡ãƒˆãƒªã®å ´åˆã¯é‡å¿ƒã‚’å–å¾—
                centroid = row.geometry.centroid
                longitude, latitude = centroid.x, centroid.y
            
            matched_records.append({
                'choume_code': matched_code,
                'choume_name': matched_name,
                'survey_year': survey_year,
                'official_price': price_per_sqm,
                'original_address': address,
                'land_area': land_area,
                'latitude': latitude,
                'longitude': longitude
            })
        
        except Exception as e:
            logger.debug(f"  âš ï¸ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            skipped_count += 1
            continue
    
    total_count = len(gdf)
    matched_count = len(matched_records)
    
    logger.info(f"[{year}å¹´] ç”ºä¸ç›®ãƒãƒƒãƒãƒ³ã‚°: {matched_count}ä»¶æˆåŠŸã€{skipped_count}ä»¶ã‚¹ã‚­ãƒƒãƒ—")
    
    if matched_count < total_count * 0.5:
        logger.warning(f"âš ï¸ [{year}å¹´] ãƒãƒƒãƒãƒ³ã‚°ç‡ãŒä½ã™ãã¾ã™ï¼ˆ{matched_count}/{total_count} = {matched_count/total_count*100:.1f}%ï¼‰")
    
    return pd.DataFrame(matched_records)


def insert_to_database(conn, df: pd.DataFrame, year: int) -> int:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥
    
    Args:
        conn: PostgreSQLæ¥ç¶š
        df: æŠ•å…¥ãƒ‡ãƒ¼ã‚¿ï¼ˆchoume_code, official_priceå«ã‚€ï¼‰
        year: èª¿æŸ»å¹´
    
    Returns:
        int: æŒ¿å…¥ä»¶æ•°
    """
    if df.empty:
        logger.warning(f"[{year}å¹´] æŠ•å…¥ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    cursor = conn.cursor()
    
    insert_count = 0
    error_count = 0
    
    # INSERT ON CONFLICT UPDATE ã‚¯ã‚¨ãƒª
    # UNIQUEåˆ¶ç´„: (choume_code, survey_year, land_type, data_source, original_address)
    # land_typeã¯NULLã‚’è¨±å®¹ï¼ˆNULLã¯ä»–ã®NULLã¨ã¯ç•°ãªã‚‹å€¤ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹ãŸã‚ã€è¤‡æ•°ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå¯èƒ½ï¼‰
    insert_query = """
        INSERT INTO land_prices (
            choume_code, survey_year, land_type, official_price, data_source,
            original_address, land_area, latitude, longitude, created_at
        ) VALUES (
            %(choume_code)s, %(survey_year)s, NULL, %(official_price)s, 'kokudo_suuchi',
            %(original_address)s, %(land_area)s, %(latitude)s, %(longitude)s, CURRENT_TIMESTAMP
        )
        ON CONFLICT (choume_code, survey_year, land_type, data_source, original_address)
        DO UPDATE SET
            official_price = EXCLUDED.official_price,
            land_area = EXCLUDED.land_area,
            latitude = EXCLUDED.latitude,
            longitude = EXCLUDED.longitude
    """
    
    for _, row in df.iterrows():
        try:
            record = {
                'choume_code': row['choume_code'],
                'survey_year': int(row['survey_year']),
                'official_price': int(row['official_price']),
                'original_address': row['original_address'],
                'land_area': row.get('land_area'),
                'latitude': row.get('latitude'),
                'longitude': row.get('longitude')
            }
            
            cursor.execute(insert_query, record)
            insert_count += 1
            
        except Exception as e:
            error_count += 1
            if error_count <= 10:  # æœ€åˆã®10ä»¶ã®ã¿ãƒ­ã‚°å‡ºåŠ›
                logger.error(f"  âŒ æŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {e} - {row.get('choume_code', 'unknown')}")
            conn.rollback()
            continue
    
    try:
        conn.commit()
        logger.info(f"[{year}å¹´] DBæŠ•å…¥å®Œäº†: {insert_count}ä»¶ï¼ˆã‚¨ãƒ©ãƒ¼: {error_count}ä»¶ï¼‰")
    except Exception as e:
        logger.error(f"[{year}å¹´] ã‚³ãƒŸãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        conn.rollback()
        insert_count = 0
    
    return insert_count


def process_year(year: int, db_config: dict, debug: bool = False) -> Tuple[bool, int]:
    """
    å˜å¹´åº¦ã®å‡¦ç†ã‚’å®Ÿè¡Œ
    
    Args:
        year: èª¿æŸ»å¹´
        db_config: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
        debug: ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
    
    Returns:
        Tuple[bool, int]: (æˆåŠŸãƒ•ãƒ©ã‚°, æŠ•å…¥ä»¶æ•°)
    """
    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        gdf = load_land_price_data(year, debug=debug)
        if gdf is None or gdf.empty:
            return False, 0
        
        # PostgreSQLæ¥ç¶š
        conn = psycopg2.connect(**db_config)
        
        try:
            # ç”ºä¸ç›®ãƒãƒƒãƒãƒ³ã‚°
            df = match_with_choume(gdf, conn, year, debug=debug)
            
            if df.empty:
                logger.warning(f"[{year}å¹´] ãƒãƒƒãƒãƒ³ã‚°çµæœãŒç©ºã§ã™")
                return False, 0
            
            # DBæŠ•å…¥
            insert_count = insert_to_database(conn, df, year)
            
            return True, insert_count
        
        finally:
            conn.close()
    
    except Exception as e:
        logger.error(f"[{year}å¹´] å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, 0


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='å›½åœŸæ•°å€¤æƒ…å ±ï¼ˆåœ°ä¾¡å…¬ç¤ºï¼‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ')
    parser.add_argument('--year', type=int, help='å‡¦ç†ã™ã‚‹å¹´åº¦ï¼ˆä¾‹: 2000ï¼‰')
    parser.add_argument('--start', type=int, help='é–‹å§‹å¹´åº¦ï¼ˆä¾‹: 2018ï¼‰')
    parser.add_argument('--end', type=int, help='çµ‚äº†å¹´åº¦ï¼ˆä¾‹: 2025ï¼‰')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆè©³ç´°ãƒ­ã‚°å‡ºåŠ›ï¼‰')
    
    args = parser.parse_args()
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        print("ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸ")
    
    # å‡¦ç†å¹´åº¦ã®æ±ºå®š
    if args.year:
        years = [args.year]
    elif args.start and args.end:
        years = list(range(args.start, args.end + 1))
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2000-2025å¹´
        years = list(range(2000, 2026))
    
    logger.info("=" * 60)
    logger.info("=== å›½åœŸæ•°å€¤æƒ…å ±ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹ ===")
    logger.info(f"å¯¾è±¡æœŸé–“: {min(years)}-{max(years)}å¹´ï¼ˆ{len(years)}å¹´åˆ†ï¼‰")
    if args.debug:
        logger.info("ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: ON")
    logger.info("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šèª­ã¿è¾¼ã¿
    db_config = load_db_config()
    
    # å„å¹´åº¦ã‚’å‡¦ç†
    total_inserted = 0
    success_years = []
    failed_years = []
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯tqdmã‚’ä½¿ã‚ãªã„ï¼ˆå‡ºåŠ›ãŒæ··ã–ã‚‹ãŸã‚ï¼‰
    year_iter = years if args.debug else tqdm(years, desc="å‡¦ç†ä¸­")
    
    for year in year_iter:
        logger.info(f"\n[{year}å¹´] å‡¦ç†é–‹å§‹")
        success, count = process_year(year, db_config, debug=args.debug)
        
        if success:
            total_inserted += count
            success_years.append(year)
        else:
            failed_years.append(year)
    
    # ã‚µãƒãƒªãƒ¼å‡ºåŠ›
    logger.info("\n" + "=" * 60)
    logger.info("=== å®Œäº†ã‚µãƒãƒªãƒ¼ ===")
    logger.info(f"ç·å‡¦ç†å¹´æ•°: {len(years)}å¹´")
    logger.info(f"æˆåŠŸ: {len(success_years)}å¹´")
    logger.info(f"å¤±æ•—: {len(failed_years)}å¹´")
    if failed_years:
        logger.info(f"å¤±æ•—å¹´åº¦: {failed_years}")
    logger.info(f"ç·æŠ•å…¥ä»¶æ•°: {total_inserted}ä»¶")
    
    if len(success_years) > 0:
        avg_matched = total_inserted / len(success_years)
        logger.info(f"å¹³å‡æŠ•å…¥ä»¶æ•°/å¹´: {avg_matched:.1f}ä»¶")
    
    logger.info("=" * 60)
    
    if len(failed_years) > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()

