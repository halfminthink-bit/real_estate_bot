#!/usr/bin/env python3
"""
å›½åœŸæ•°å€¤æƒ…å ±ï¼ˆ2018-2025å¹´ç‰ˆï¼‰ã‚’ä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå¼·åŠ›ãƒãƒƒãƒãƒ³ã‚°ç‰ˆï¼‰
"""

import json
import psycopg2
import yaml
from pathlib import Path
from dotenv import load_dotenv
import os
import re
import sys

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ç”¨é€”åœ°åŸŸã‚³ãƒ¼ãƒ‰ã®å¤‰æ›ãƒãƒƒãƒ—
LAND_USE_MAP = {
    "1ä½å°‚": "1ä½å°‚", "2ä½å°‚": "2ä½å°‚",
    "1ä¸­å°‚": "1ä¸­å°‚", "2ä¸­å°‚": "2ä¸­å°‚",
    "1ä½å±…": "1ä½å±…", "2ä½å±…": "2ä½å±…",
    "æº–ä½å±…": "æº–ä½å±…", "è¿‘å•†": "è¿‘å•†",
    "å•†æ¥­": "å•†æ¥­", "æº–å·¥": "æº–å·¥",
    "å·¥æ¥­": "å·¥æ¥­", "å·¥å°‚": "å·¥å°‚",
}

# æ¼¢æ•°å­—å¤‰æ›ç”¨ãƒãƒƒãƒ—
KANJI_NUM_MAP = str.maketrans('ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹', '123456789')
REV_KANJI_NUM_MAP = {
    '1': 'ä¸€', '2': 'äºŒ', '3': 'ä¸‰', '4': 'å››', '5': 'äº”',
    '6': 'å…­', '7': 'ä¸ƒ', '8': 'å…«', '9': 'ä¹'
}

def load_db_config():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
    config_path = project_root / 'config' / 'database.yml'
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return {
        'host': os.getenv('DB_HOST', config['postgresql'].get('host', 'localhost')),
        'port': int(os.getenv('DB_PORT', config['postgresql'].get('port', 5432))),
        'database': os.getenv('DB_NAME', config['postgresql'].get('database', 'real_estate_dev')),
        'user': os.getenv('DB_USER', config['postgresql'].get('user', 'postgres')),
        'password': os.getenv('DB_PASSWORD', config['postgresql'].get('password', 'postgres'))
    }

def normalize_string(s):
    """æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–ï¼ˆå…¨è§’è‹±æ•°â†’åŠè§’ã€ã‚¹ãƒšãƒ¼ã‚¹å‰Šé™¤ï¼‰"""
    if not s:
        return ""
    s = s.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½š', 
                                  '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'))
    s = s.replace(' ', '').replace('ã€€', '')
    return s

def normalize_address(address):
    """ä½æ‰€ã‚’æ­£è¦åŒ–"""
    address = normalize_string(address)
    # ä¸–ç”°è°·åŒºãŒå«ã¾ã‚Œã¦ã„ãŸã‚‰å‰Šé™¤ï¼ˆçªåˆç²¾åº¦å‘ä¸Šã®ãŸã‚ï¼‰
    if 'ä¸–ç”°è°·åŒº' in address:
        parts = address.split('ä¸–ç”°è°·åŒº')
        if len(parts) > 1:
            address = parts[1].strip()
    # ã€Œå­—ã€ã€Œå¤§å­—ã€ã‚’å‰Šé™¤
    address = address.replace('å¤§å­—', '').replace('å­—', '')
    return address

def num_to_kanji(s):
    """æ•°å­—ãŒå«ã¾ã‚Œã‚‹æ–‡å­—åˆ—ã®æ•°å­—éƒ¨åˆ†ã‚’æ¼¢æ•°å­—ã«å¤‰æ›ï¼ˆä¾‹: 2ä¸ç›® -> äºŒä¸ç›®ï¼‰"""
    res = ""
    for char in s:
        res += REV_KANJI_NUM_MAP.get(char, char)
    return res
def extract_choume_candidates(address):
    """
    ä½æ‰€ã‹ã‚‰ç”ºä¸ç›®åã®å€™è£œãƒªã‚¹ãƒˆã‚’è¿”ã™ï¼ˆå¼·åŒ–ç‰ˆï¼‰
    """
    if not address:
        return []
    
    # 1. åŸºæœ¬æ­£è¦åŒ–ï¼ˆå…¨è§’è‹±æ•°â†’åŠè§’ã€ã‚¹ãƒšãƒ¼ã‚¹å‰Šé™¤ï¼‰
    normalized = normalize_address(address)
    
    # 2. ãƒã‚¤ãƒ•ãƒ³æ­£è¦åŒ–ï¼ˆã“ã“ã‚’å¼·åŒ–ï¼‰
    # å…¨è§’ãƒã‚¤ãƒ•ãƒ³(ï¼)ã€ãƒã‚¤ãƒŠã‚¹(âˆ’)ã€é•·éŸ³(ãƒ¼)ã€ãƒ€ãƒƒã‚·ãƒ¥(â€)ãªã©ã‚’å…¨ã¦åŠè§’ãƒã‚¤ãƒ•ãƒ³(-)ã«ç½®æ›
    normalized = re.sub(r'[ï¼âˆ’ãƒ¼â€]', '-', normalized)
    
    candidates = []

    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: "â—¯â—¯Nä¸ç›®" ã®å½¢å¼
    # ä¾‹: "ç­‰ã€…åŠ›5ä¸ç›®..."
    match1 = re.search(r'^(.+?\d+)ä¸ç›®', normalized)
    if match1:
        base = match1.group(1) + "ä¸ç›®"
        candidates.append(base)
        candidates.append(num_to_kanji(base)) # æ¼¢æ•°å­—ç‰ˆï¼ˆç­‰ã€…åŠ›äº”ä¸ç›®ï¼‰

    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: "â—¯â—¯N-" ã®å½¢å¼ï¼ˆã“ã“ãŒ2018-2020å¹´ç”¨ï¼‰
    # ä¾‹: "å–œå¤šè¦‹9-19-6" -> "å–œå¤šè¦‹9-" ã«ãƒãƒƒãƒ
    match2 = re.search(r'^(.+?)(\d+)-', normalized)
    if match2:
        area_name = match2.group(1)   # å–œå¤šè¦‹
        choume_num = match2.group(2)  # 9
        
        # "å–œå¤šè¦‹9ä¸ç›®"
        base = f"{area_name}{choume_num}ä¸ç›®"
        candidates.append(base)
        
        # "å–œå¤šè¦‹ä¹ä¸ç›®" (æ¼¢æ•°å­—å¤‰æ›)
        candidates.append(f"{area_name}{num_to_kanji(choume_num)}ä¸ç›®")
        
        # "å–œå¤šè¦‹" (ä¸ç›®ãªã—ã®åœ°åŸŸç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
        candidates.append(area_name)

    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: æ•°å­—ãŒå«ã¾ã‚Œãªã„å ´åˆï¼ˆå˜ãªã‚‹ç”ºåï¼‰
    # ä¾‹: "å¤§è”µ..."
    match3 = re.search(r'^(\D+)', normalized)
    if match3:
        candidates.append(match3.group(1))

    # é‡è¤‡ã‚’é™¤å»ã—ã¦ãƒªã‚¹ãƒˆåŒ–
    return list(set(candidates))
def get_field_mapping(year):
    """å¹´åº¦åˆ¥ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°"""
    if year <= 2020:
        return {
            'address': 'L01_023',
            'city_name': 'L01_022',
            'land_area': 'L01_024',
            'road_direction': 'L01_037',
            'road_width': 'L01_038',
            'nearest_station': 'L01_045',
            'station_distance': 'L01_046',
            'land_use': 'L01_047',
            'building_coverage': 'L01_052',
            'floor_area_ratio': 'L01_053',
            'official_price': 'L01_006',
        }
    elif year == 2021:
        return {
            'address': 'L01_023',
            'city_name': 'L01_022',
            'land_area': 'L01_024',
            'road_direction': 'L01_037',
            'road_width': 'L01_038',
            'nearest_station': 'L01_045',
            'station_distance': 'L01_046',
            'land_use': 'L01_047',
            'building_coverage': 'L01_052',
            'floor_area_ratio': 'L01_053',
            'official_price': 'L01_006',
        }
    elif year <= 2023:
        return {
            'address': 'L01_024',
            'city_name': 'L01_023',
            'land_area': 'L01_026',
            'road_direction': 'L01_040',
            'road_width': 'L01_041',
            'nearest_station': 'L01_048',
            'station_distance': 'L01_049',
            'land_use': 'L01_050',
            'building_coverage': 'L01_056',
            'floor_area_ratio': 'L01_057',
            'official_price': 'L01_006',
        }
    else:
        return {
            'address': 'L01_025',
            'city_name': 'L01_024',
            'land_area': 'L01_027',
            'road_direction': 'L01_041',
            'road_width': 'L01_042',
            'nearest_station': 'L01_048',
            'station_distance': 'L01_050',
            'land_use': 'L01_051',
            'building_coverage': 'L01_057',
            'floor_area_ratio': 'L01_058',
            'official_price': 'L01_006',
        }

def extract_from_geojson(geojson_path, year=None):
    print(f"\nğŸ“‚ {geojson_path.name} ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    if year is None:
        import re
        match = re.search(r'(\d{4})_13', str(geojson_path))
        year = int(match.group(1)) if match else 2021
    
    fields = get_field_mapping(year)
    with open(geojson_path, 'r', encoding='utf-8') as f:
        geojson_data = json.load(f)
    
    features = geojson_data.get('features', [])
    print(f"   ç·ä»¶æ•°: {len(features)}ä»¶")
    
    result = {}
    for feature in features:
        props = feature['properties']
        
        # ä½æ‰€å–å¾—
        address = props.get(fields['address'], '')
        if not address: address = props.get('L01_023', '')
        if not address: continue
        
        # ä¸–ç”°è°·åŒºãƒ•ã‚£ãƒ«ã‚¿
        city_name = props.get(fields['city_name'], '')
        if 'ä¸–ç”°è°·' not in address and 'ä¸–ç”°è°·' not in city_name:
            continue
        
        # åœ°ä¾¡
        price_val = props.get(fields.get('official_price', 'L01_006'), '')
        try:
            official_price = int(price_val)
        except:
            official_price = None

        def safe_val(key, cast=int):
            v = props.get(fields.get(key), '')
            try: return cast(v)
            except: return None

        normalized_addr = normalize_address(address)
        result[normalized_addr] = {
            'land_use': LAND_USE_MAP.get(props.get(fields['land_use'], ''), None),
            'building_coverage_ratio': safe_val('building_coverage'),
            'floor_area_ratio': safe_val('floor_area_ratio'),
            'road_direction': props.get(fields['road_direction'], None),
            'road_width': safe_val('road_width', float),
            'land_area': safe_val('land_area'),
            'nearest_station': props.get(fields['nearest_station'], None),
            'station_distance': safe_val('station_distance'),
            'official_price': official_price,
            'original_address': address
        }
    
    print(f"   æŠ½å‡ºå®Œäº†: {len(result)}ä»¶ï¼ˆä¸–ç”°è°·åŒºã®ã¿ï¼‰")
    return result

def import_year_data(conn, year, geojson_data):
    print(f"\nğŸ”„ {year}å¹´åº¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­...")
    cur = conn.cursor()
    
    # ãƒã‚¹ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½œæˆ (æ­£è¦åŒ–ã‚­ãƒ¼ -> ã‚³ãƒ¼ãƒ‰)
    cur.execute("SELECT choume_name, choume_code FROM choume")
    choume_map = {}
    for row in cur.fetchall():
        choume_map[normalize_string(row[0])] = row[1]
    
    # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰å–å¾—
    cur.execute("SELECT id, original_address FROM land_prices WHERE survey_year = %s", (year,))
    existing_map = {normalize_address(addr): rid for rid, addr in cur.fetchall() if addr}
    
    stats = {'update': 0, 'insert': 0, 'skip': 0, 'error': 0}
    debug_skips = []

    for norm_addr, data in geojson_data.items():
        try:
            # UPDATE
            if norm_addr in existing_map:
                cur.execute("""
                    UPDATE land_prices SET 
                        land_use=%s, building_coverage_ratio=%s, floor_area_ratio=%s,
                        road_direction=%s, road_width=%s, land_area=%s,
                        nearest_station=%s, station_distance=%s,
                        official_price=COALESCE(official_price, %s)
                    WHERE id=%s
                """, (
                    data['land_use'], data['building_coverage_ratio'], data['floor_area_ratio'],
                    data['road_direction'], data['road_width'], data['land_area'],
                    data['nearest_station'], data['station_distance'],
                    data['official_price'], existing_map[norm_addr]
                ))
                stats['update'] += 1
            
            # INSERT
            else:
                # å€™è£œãƒªã‚¹ãƒˆã‹ã‚‰ãƒãƒƒãƒã™ã‚‹ã‚‚ã®ã‚’æ¢ã™
                candidates = extract_choume_candidates(data['original_address'])
                choume_code = None
                matched_name = None
                
                for cand in candidates:
                    # æ­£è¦åŒ–ã—ãŸã‚­ãƒ¼ã§æ¤œç´¢
                    norm_cand = normalize_string(cand)
                    if norm_cand in choume_map:
                        choume_code = choume_map[norm_cand]
                        matched_name = cand
                        break
                
                if not choume_code:
                    stats['skip'] += 1
                    if len(debug_skips) < 3: # æœ€åˆã®3ä»¶ã ã‘è©³ç´°ãƒ­ã‚°ä¿å­˜
                        debug_skips.append(f"Org: {data['original_address']} -> Cands: {candidates}")
                    continue

                cur.execute("""
                    INSERT INTO land_prices (
                        choume_code, survey_year, official_price,
                        land_use, building_coverage_ratio, floor_area_ratio,
                        road_direction, road_width, land_area,
                        nearest_station, station_distance, original_address, data_source
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, 'kokudo_geojson')
                    ON CONFLICT (choume_code, survey_year, land_type, data_source, original_address)
                    DO UPDATE SET official_price = EXCLUDED.official_price
                """, (
                    choume_code, year, data['official_price'],
                    data['land_use'], data['building_coverage_ratio'], data['floor_area_ratio'],
                    data['road_direction'], data['road_width'], data['land_area'],
                    data['nearest_station'], data['station_distance'], data['original_address']
                ))
                stats['insert'] += 1

        except Exception as e:
            stats['error'] += 1
            print(f"Error: {e}")

    conn.commit()
    cur.close()
    
    print(f"   âœ… UPDATE: {stats['update']} / INSERT: {stats['insert']}")
    print(f"   âš ï¸ SKIP: {stats['skip']} / ERROR: {stats['error']}")
    if debug_skips:
        print("   [Skip Sample Debug]")
        for msg in debug_skips:
            print(f"     - {msg}")
    
    return stats['update'] + stats['insert']

def main():
    print("=" * 60 + "\nå›½åœŸæ•°å€¤æƒ…å ±ï¼ˆ2018-2025å¹´ç‰ˆï¼‰ä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆä¿®æ­£ç‰ˆï¼‰\n" + "=" * 60)
    
    base_path = project_root / "data" / "raw" / "national" / "kokudo_suuchi"
    # â€»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¯ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„
    geojson_files = {
        y: base_path / f"{y}_13" / (f"L01-{str(y)[2:]}_13_GML" if y!=2022 and y!=2019 else f"L01-{str(y)[2:]}_13") / f"L01-{str(y)[2:]}_13.geojson"
        for y in range(2018, 2026)
    }
    # ãƒ‘ã‚¹å¾®èª¿æ•´ç”¨ï¼ˆå®Ÿéš›ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã«åˆã‚ã›ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    for y in geojson_files:
        if not geojson_files[y].exists():
             # ãƒ‘ã‚¿ãƒ¼ãƒ³B: GMLãƒ•ã‚©ãƒ«ãƒ€ãªã—
             alt = base_path / f"{y}_13" / f"L01-{str(y)[2:]}_13.geojson"
             if alt.exists(): geojson_files[y] = alt

    db_config = load_db_config()
    try:
        conn = psycopg2.connect(**db_config)
    except Exception as e:
        print(f"DBæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return

    total = 0
    for year in range(2018, 2026):
        path = geojson_files.get(year)
        if path and path.exists():
            data = extract_from_geojson(path, year)
            if data:
                total += import_year_data(conn, year, data)
        else:
            print(f"\nâš ï¸ {year}å¹´ãƒ•ã‚¡ã‚¤ãƒ«ãªã—: {path}")

    conn.close()
    print(f"\nå®Œäº†: åˆè¨ˆ {total} ä»¶å‡¦ç†")

if __name__ == "__main__":
    main()