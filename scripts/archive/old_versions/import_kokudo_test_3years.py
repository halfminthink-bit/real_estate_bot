#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›½åœŸæ•°å€¤æƒ…å ±ï¼ˆåœ°ä¾¡å…¬ç¤ºãƒ‡ãƒ¼ã‚¿ï¼‰ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Step 1: 3å¹´åˆ†ï¼ˆ2000å¹´ã€2016å¹´ã€2020å¹´ï¼‰ã§ãƒ†ã‚¹ãƒˆ
"""

import geopandas as gpd
import psycopg2
import yaml
from pathlib import Path
from dotenv import load_dotenv
import os
import sys
import re
from datetime import date

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def load_db_config():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
    config_path = project_root / 'config' / 'database.yml'
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return {
        'host': os.getenv('DB_HOST', config['postgresql'].get('host', 'localhost')),
        'port': int(os.getenv('DB_PORT', config['postgresql'].get('port', 5432))),
        'database': os.getenv('DB_NAME', config['postgresql'].get('database', 'real_estate_dev')),
        'user': os.getenv('DB_USER', config['postgresql'].get('user', 'postgres')),
        'password': os.getenv('DB_PASSWORD', config['postgresql'].get('password', 'postgres'))
    }


def normalize_address(address):
    """ä½æ‰€ã‚’æ­£è¦åŒ–"""
    if not address:
        return ""
    
    # å…¨è§’æ•°å­—ã‚’åŠè§’ã«
    address = address.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
    
    # ã‚¹ãƒšãƒ¼ã‚¹å‰Šé™¤
    address = address.replace(' ', '').replace('ã€€', '')
    
    # ã€Œæ±äº¬éƒ½ã€ã‚’å‰Šé™¤
    address = address.replace('æ±äº¬éƒ½', '')
    
    # ã€Œä¸–ç”°è°·åŒºã€ã‚’å‰Šé™¤
    if 'ä¸–ç”°è°·åŒº' in address:
        address = address.split('ä¸–ç”°è°·åŒº')[1]
    
    # å…¨è§’ãƒã‚¤ãƒ•ãƒ³ãƒ»ãƒã‚¤ãƒŠã‚¹ã‚’åŠè§’ãƒã‚¤ãƒ•ãƒ³ã«çµ±ä¸€
    address = address.replace('ï¼', '-').replace('âˆ’', '-').replace('â€', '-')
    
    # ãƒã‚¤ãƒ•ãƒ³å½¢å¼ã‚’ä¸ç›®ç•ªå½¢å¼ã«å¤‰æ›
    parts = re.split(r'[-]', address)
    if len(parts) == 3:
        # 3åˆ†å‰²ã•ã‚ŒãŸå ´åˆï¼šç”ºå-ä¸ç›®-ç•ªåœ°
        address = f"{parts[0]}ä¸ç›®{parts[1]}ç•ª{parts[2]}"
    elif len(parts) == 2:
        # 2åˆ†å‰²ã•ã‚ŒãŸå ´åˆï¼šç”ºå-ç•ªåœ°
        address = f"{parts[0]}ç•ª{parts[1]}"
    
    # ã€Œå¤–ã€ã‚’å‰Šé™¤ï¼ˆãƒãƒƒãƒãƒ³ã‚°ã®ãŸã‚ï¼‰
    address = address.replace('å¤–', '')
    
    return address.strip()


def create_table(conn):
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
    cur = conn.cursor()
    
    create_table_sql = """
    CREATE TABLE IF NOT EXISTS land_prices_kokudo (
        id SERIAL PRIMARY KEY,
        choume_code VARCHAR(11),
        survey_year INTEGER NOT NULL,
        official_price INTEGER,  -- NULLè¨±å¯ï¼ˆ2020å¹´ä»¥é™ã¯ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
        data_source VARCHAR(50) NOT NULL DEFAULT 'åœ°ä¾¡å…¬ç¤º',
        original_address TEXT,
        land_area INTEGER,
        land_use VARCHAR(50),
        building_coverage_ratio INTEGER,
        floor_area_ratio INTEGER,
        road_direction VARCHAR(10),
        road_width NUMERIC(5,1),
        nearest_station VARCHAR(100),
        station_distance INTEGER,
        latitude NUMERIC(10,7),
        longitude NUMERIC(11,7),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(survey_year, original_address)
    );
    
    CREATE INDEX IF NOT EXISTS idx_land_prices_kokudo_year ON land_prices_kokudo(survey_year);
    CREATE INDEX IF NOT EXISTS idx_land_prices_kokudo_choume ON land_prices_kokudo(choume_code);
    """
    
    cur.execute(create_table_sql)
    conn.commit()
    cur.close()
    print("âœ… ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†: land_prices_kokudo")


def load_shapefile_data(filepath, year, field_mapping):
    """Shapefileã¾ãŸã¯GeoJSONã‚’èª­ã¿è¾¼ã‚“ã§ä¸–ç”°è°·åŒºã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    print(f"  ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {filepath.name}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ã¦èª­ã¿è¾¼ã¿
    if filepath.suffix == '.shp':
        gdf = gpd.read_file(filepath, encoding='shift-jis')
    else:
        gdf = gpd.read_file(filepath, encoding='utf-8')
    
    print(f"    ç·ä»¶æ•°: {len(gdf):,}ä»¶")
    
    # ä¸–ç”°è°·åŒºã‚’ãƒ•ã‚£ãƒ«ã‚¿
    city_code_field = field_mapping['city_code']
    setagaya = gdf[gdf[city_code_field].astype(str) == '13112']
    print(f"    ä¸–ç”°è°·åŒº: {len(setagaya):,}ä»¶")
    
    # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
    records = []
    for idx, row in setagaya.iterrows():
        try:
            # ä½æ‰€ã‚’å–å¾—
            address_raw = row.get(field_mapping['address'], '')
            if pd.isna(address_raw) or address_raw == '':
                continue
            
            # ä½æ‰€ã‚’æ­£è¦åŒ–
            normalized_address = normalize_address(str(address_raw))
            
            # ä¾¡æ ¼ã‚’å–å¾—
            price = None
            if 'price' in field_mapping:
                price_raw = row.get(field_mapping['price'])
                # GeoJSONã¯å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ–‡å­—åˆ—ãªã®ã§ã€ç„¡åŠ¹å€¤ã‚’ãƒã‚§ãƒƒã‚¯
                if pd.notna(price_raw) and str(price_raw) not in ['', '_', 'false', 'None']:
                    try:
                        price = int(float(price_raw))
                        # ä¾¡æ ¼ã®å˜ä½ç¢ºèª: ã‚‚ã—å°ã•ã™ãã‚‹å ´åˆã¯Ã—100
                        # ä¸–ç”°è°·åŒºã®å¹³å‡åœ°ä¾¡ã¯50-60ä¸‡å††/ã¡ç¨‹åº¦
                        if price < 10000:  # 1ä¸‡å††/ã¡æœªæº€ã¯ç•°å¸¸ï¼ˆå˜ä½ãŒ100å††å˜ä½ã®å¯èƒ½æ€§ï¼‰
                            price = price * 100
                    except (ValueError, TypeError):
                        price = None
            
            # åœ°ç©ã‚’å–å¾—
            land_area = None
            if 'land_area' in field_mapping:
                land_area_raw = row.get(field_mapping['land_area'])
                if pd.notna(land_area_raw):
                    try:
                        land_area = int(float(land_area_raw))
                    except (ValueError, TypeError):
                        land_area = None
            
            # ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‹ã‚‰åº§æ¨™ã‚’å–å¾—
            latitude = None
            longitude = None
            if hasattr(row, 'geometry') and row.geometry is not None:
                try:
                    if row.geometry.geom_type == 'Point':
                        longitude, latitude = row.geometry.x, row.geometry.y
                    else:
                        # Polygonç­‰ã®å ´åˆã¯é‡å¿ƒã‚’å–å¾—
                        centroid = row.geometry.centroid
                        longitude, latitude = centroid.x, centroid.y
                except:
                    pass
            
            record = {
                'survey_year': year,
                'original_address': normalized_address,
                'official_price': price,
                'land_area': land_area,
                'data_source': 'åœ°ä¾¡å…¬ç¤º',
                'latitude': latitude,
                'longitude': longitude,
                'created_at': date.today()
            }
            
            # 2020å¹´ä»¥é™ã®è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            if year >= 2020:
                if 'road_direction' in field_mapping:
                    val = row.get(field_mapping['road_direction'])
                    record['road_direction'] = str(val) if pd.notna(val) and val != '_' else None
                
                if 'road_width' in field_mapping:
                    val = row.get(field_mapping['road_width'])
                    if pd.notna(val) and val != '_' and val != 0:
                        try:
                            record['road_width'] = float(val)
                        except:
                            record['road_width'] = None
                    else:
                        record['road_width'] = None
                
                if 'nearest_station' in field_mapping:
                    val = row.get(field_mapping['nearest_station'])
                    record['nearest_station'] = str(val) if pd.notna(val) and val != '_' else None
                
                if 'station_distance' in field_mapping:
                    val = row.get(field_mapping['station_distance'])
                    if pd.notna(val) and val != '_' and val != 0:
                        try:
                            record['station_distance'] = int(float(val))
                        except:
                            record['station_distance'] = None
                    else:
                        record['station_distance'] = None
                
                if 'land_use' in field_mapping:
                    val = row.get(field_mapping['land_use'])
                    record['land_use'] = str(val) if pd.notna(val) and val != '_' else None
                
                if 'building_coverage' in field_mapping:
                    val = row.get(field_mapping['building_coverage'])
                    if pd.notna(val) and val != '_' and val != 0:
                        try:
                            record['building_coverage_ratio'] = int(float(val))
                        except:
                            record['building_coverage_ratio'] = None
                    else:
                        record['building_coverage_ratio'] = None
                
                if 'floor_area_ratio' in field_mapping:
                    val = row.get(field_mapping['floor_area_ratio'])
                    if pd.notna(val) and val != '_' and val != 0:
                        try:
                            record['floor_area_ratio'] = int(float(val))
                        except:
                            record['floor_area_ratio'] = None
                    else:
                        record['floor_area_ratio'] = None
            
            records.append(record)
            
        except Exception as e:
            print(f"    âš ï¸  è¡Œ {idx} ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return records


def import_to_db(conn, records):
    """PostgreSQLã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    if not records:
        return 0
    
    cur = conn.cursor()
    
    insert_sql = """
    INSERT INTO land_prices_kokudo (
        survey_year, original_address, official_price, land_area,
        data_source, latitude, longitude, created_at,
        land_use, building_coverage_ratio, floor_area_ratio,
        road_direction, road_width, nearest_station, station_distance
    ) VALUES (
        %(survey_year)s, %(original_address)s, %(official_price)s, %(land_area)s,
        %(data_source)s, %(latitude)s, %(longitude)s, %(created_at)s,
        %(land_use)s, %(building_coverage_ratio)s, %(floor_area_ratio)s,
        %(road_direction)s, %(road_width)s, %(nearest_station)s, %(station_distance)s
    )
    ON CONFLICT (survey_year, original_address) DO UPDATE SET
        official_price = EXCLUDED.official_price,
        land_area = EXCLUDED.land_area,
        land_use = EXCLUDED.land_use,
        building_coverage_ratio = EXCLUDED.building_coverage_ratio,
        floor_area_ratio = EXCLUDED.floor_area_ratio,
        road_direction = EXCLUDED.road_direction,
        road_width = EXCLUDED.road_width,
        nearest_station = EXCLUDED.nearest_station,
        station_distance = EXCLUDED.station_distance
    """
    
    success_count = 0
    error_count = 0
    
    for record in records:
        try:
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
            record.setdefault('land_use', None)
            record.setdefault('building_coverage_ratio', None)
            record.setdefault('floor_area_ratio', None)
            record.setdefault('road_direction', None)
            record.setdefault('road_width', None)
            record.setdefault('nearest_station', None)
            record.setdefault('station_distance', None)
            
            cur.execute(insert_sql, record)
            success_count += 1
        except Exception as e:
            print(f"    âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            print(f"       ãƒ‡ãƒ¼ã‚¿: {record.get('original_address', 'N/A')}")
            error_count += 1
            conn.rollback()
            continue
    
    conn.commit()
    cur.close()
    
    return success_count, error_count


def main():
    print("=" * 80)
    print("å›½åœŸæ•°å€¤æƒ…å ±ï¼ˆåœ°ä¾¡å…¬ç¤ºãƒ‡ãƒ¼ã‚¿ï¼‰ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    print("Step 1: 3å¹´åˆ†ï¼ˆ2000å¹´ã€2016å¹´ã€2020å¹´ï¼‰")
    print("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    db_config = load_db_config()
    try:
        conn = psycopg2.connect(**db_config)
        print("\nâœ… PostgreSQLã«æ¥ç¶šã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ PostgreSQLæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    create_table(conn)
    
    # ãƒ†ã‚¹ãƒˆå¯¾è±¡å¹´åº¦ã®è¨­å®š
    base_path = project_root / "data" / "raw" / "national" / "kokudo_suuchi"
    
    test_configs = [
        {
            'year': 2000,
            'filepath': base_path / "2000_13" / "L01-00_13-g_LandPrice.shp",
            'field_mapping': {
                'city_code': 'L01_017',
                'city_name': 'L01_018',
                'address': 'L01_019',
                'price': 'L01_006',
                'land_area': 'L01_020',
            }
        },
        {
            'year': 2016,
            'filepath': base_path / "2016_13" / "L01-16_13.shp",
            'field_mapping': {
                'city_code': 'L01_017',
                'city_name': 'L01_018',
                'address': 'L01_019',
                'price': 'L01_006',
                'land_area': 'L01_020',
            }
        },
        {
            'year': 2020,
            'filepath': base_path / "2020_13" / "L01-20_13_GML" / "L01-20_13.geojson",
            'field_mapping': {
                'city_code': 'L01_021',
                'city_name': 'L01_022',
                'address': 'L01_023',
                'price': 'L01_006',  # ä¾¡æ ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¿½åŠ 
                'land_area': 'L01_024',
                'road_direction': 'L01_037',
                'road_width': 'L01_038',
                'nearest_station': 'L01_045',
                'station_distance': 'L01_046',
                'land_use': 'L01_047',
                'building_coverage': 'L01_052',
                'floor_area_ratio': 'L01_053',
            }
        }
    ]
    
    total_success = 0
    total_error = 0
    
    for config in test_configs:
        print(f"\n{'='*80}")
        print(f"ğŸ“‚ {config['year']}å¹´ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­...")
        print('='*80)
        
        filepath = config['filepath']
        if not filepath.exists():
            print(f"  âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
            continue
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        try:
            records = load_shapefile_data(filepath, config['year'], config['field_mapping'])
            print(f"  âœ… ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Œäº†: {len(records)}ä»¶")
        except Exception as e:
            print(f"  âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            continue
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        success, error = import_to_db(conn, records)
        total_success += success
        total_error += error
        
        print(f"  âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: æˆåŠŸ {success}ä»¶ã€ã‚¨ãƒ©ãƒ¼ {error}ä»¶")
    
    conn.close()
    
    print("\n" + "=" * 80)
    print(f"âœ… åˆè¨ˆ {total_success}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
    if total_error > 0:
        print(f"âš ï¸  ã‚¨ãƒ©ãƒ¼: {total_error}ä»¶")
    print("=" * 80)


if __name__ == '__main__':
    import pandas as pd  # geopandasã®ä¾å­˜é–¢ä¿‚ã§å¿…è¦
    main()

