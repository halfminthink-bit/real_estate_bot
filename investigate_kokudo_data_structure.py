#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å›½åœŸæ•°å€¤æƒ…å ±ï¼ˆåœ°ä¾¡å…¬ç¤ºãƒ‡ãƒ¼ã‚¿ï¼‰2000-2025å¹´ ãƒ‡ãƒ¼ã‚¿æ§‹é€ èª¿æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Phase 2: ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®èª¿æŸ»
"""

import geopandas as gpd
import json
from pathlib import Path

def get_file_path(year):
    """æŒ‡å®šå¹´åº¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—"""
    base_path = Path('data/raw/national/kokudo_suuchi')
    year_short = f"{year % 100:02d}"
    year_dir = base_path / f"{year}_13"
    
    if not year_dir.exists():
        return None
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³A: 2000-2011å¹´
    if 2000 <= year <= 2011:
        shp_file = year_dir / f"L01-{year_short}_13-g_LandPrice.shp"
        if shp_file.exists():
            return shp_file
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³B: 2012-2014, 2016-2017, 2019, 2022å¹´
    if year in [2012, 2013, 2014, 2016, 2017, 2019, 2022]:
        shp_file = year_dir / f"L01-{year_short}_13.shp"
        if shp_file.exists():
            return shp_file
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³C: 2015, 2018, 2020-2021, 2023-2025å¹´ï¼ˆã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ï¼‰
    if year in [2015, 2018, 2020, 2021, 2023, 2024, 2025]:
        subdir = year_dir / f"L01-{year_short}_13_GML"
        if subdir.exists():
            # GeoJSONã‚’å„ªå…ˆ
            geojson_file = subdir / f"L01-{year_short}_13.geojson"
            if geojson_file.exists():
                return geojson_file
            # Shapefile
            shp_file = subdir / f"L01-{year_short}_13.shp"
            if shp_file.exists():
                return shp_file
    
    # 2019å¹´ã¯ç›´æ¥GeoJSONãŒã‚ã‚‹å¯èƒ½æ€§
    if year == 2019:
        geojson_file = year_dir / f"L01-{year_short}_13.geojson"
        if geojson_file.exists():
            return geojson_file
    
    return None

def investigate_year(year):
    """æŒ‡å®šå¹´åº¦ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’èª¿æŸ»"""
    filepath = get_file_path(year)
    
    if not filepath or not filepath.exists():
        print(f"\n{'='*70}")
        print(f"âŒ {year}å¹´: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    print(f"\n{'='*70}")
    print(f"ğŸ“‚ {year}å¹´: {filepath.name}")
    print('='*70)
    
    try:
        # Shapefileã¾ãŸã¯GeoJSONã‚’èª­ã¿è¾¼ã¿
        if filepath.suffix == '.shp':
            gdf = gpd.read_file(filepath, encoding='shift-jis')
        else:
            gdf = gpd.read_file(filepath, encoding='utf-8')
        
        print(f"\nâœ… èª­ã¿è¾¼ã¿æˆåŠŸ")
        print(f"   ç·ä»¶æ•°: {len(gdf):,}ä»¶")
        print(f"   ã‚«ãƒ©ãƒ æ•°: {len(gdf.columns)}å€‹")
        
        # ã‚«ãƒ©ãƒ ä¸€è¦§ï¼ˆæœ€åˆã®30å€‹ï¼‰
        print(f"\nğŸ“‹ ã‚«ãƒ©ãƒ ä¸€è¦§ï¼ˆæœ€åˆã®30å€‹ï¼‰:")
        for i, col in enumerate(gdf.columns[:30], 1):
            sample_value = gdf[col].iloc[0] if len(gdf) > 0 else None
            if sample_value is not None:
                val_str = str(sample_value)[:50]
            else:
                val_str = 'None'
            print(f"   {i:2d}. {col:20s} : {val_str}")
        
        if len(gdf.columns) > 30:
            print(f"   ... (æ®‹ã‚Š{len(gdf.columns) - 30}å€‹ã®ã‚«ãƒ©ãƒ )")
        
        # ä¸–ç”°è°·åŒºã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
        setagaya_cols = []
        for col in gdf.columns:
            try:
                # æœ€åˆã®1000ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
                sample_values = gdf[col].head(1000).astype(str)
                if any('13112' in str(val) for val in sample_values):
                    setagaya_cols.append(col)
            except:
                pass
        
        if setagaya_cols:
            print(f"\nğŸ” å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰å€™è£œ: {setagaya_cols}")
            
            # ä¸–ç”°è°·åŒºã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            code_col = setagaya_cols[0]
            setagaya = gdf[gdf[code_col].astype(str) == '13112']
            print(f"   ä¸–ç”°è°·åŒº: {len(setagaya):,}ä»¶")
            
            if len(setagaya) > 0:
                # ä½æ‰€ãƒ»ä¾¡æ ¼ã®ã‚«ãƒ©ãƒ ã‚’ç‰¹å®š
                print(f"\nğŸ“ ä¸–ç”°è°·åŒºã‚µãƒ³ãƒ—ãƒ«ï¼ˆ1ä»¶ï¼‰:")
                sample = setagaya.iloc[0]
                for col in gdf.columns[:40]:
                    val = str(sample[col])
                    if 'æ±äº¬' in val or 'ä¸–ç”°è°·' in val or (len(val) > 15 and not val.startswith('0')):
                        print(f"   {col:20s}: {val[:70]}")
        
        # é‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç‰¹å®š
        print(f"\nğŸ¯ é‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç‰¹å®š:")
        important_fields = {}
        
        # å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰
        for col in gdf.columns:
            try:
                sample_values = gdf[col].head(100).astype(str)
                if any('13112' in str(val) for val in sample_values):
                    important_fields['city_code'] = col
                    break
            except:
                pass
        
        # ä½æ‰€ï¼ˆæ±äº¬éƒ½ã‚’å«ã‚€é•·ã„æ–‡å­—åˆ—ï¼‰
        for col in gdf.columns:
            try:
                val = str(gdf[col].iloc[0] if len(gdf) > 0 else '')
                if 'æ±äº¬éƒ½' in val and len(val) > 10:
                    important_fields['address'] = col
                    break
            except:
                pass
        
        # ä¾¡æ ¼ï¼ˆå¤§ããªæ•°å€¤ï¼‰
        for col in gdf.columns:
            try:
                if gdf[col].dtype in ['int64', 'float64']:
                    val = gdf[col].iloc[0] if len(gdf) > 0 else 0
                    if 10000 < val < 10000000:  # ä¾¡æ ¼ã®ç¯„å›²ï¼ˆå††/ã¡ï¼‰
                        important_fields['price'] = col
                        break
            except:
                pass
        
        print(f"   å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰: {important_fields.get('city_code', 'ä¸æ˜')}")
        print(f"   ä½æ‰€:          {important_fields.get('address', 'ä¸æ˜')}")
        print(f"   ä¾¡æ ¼:          {important_fields.get('price', 'ä¸æ˜')}")
        
        return {
            'year': year,
            'total_count': len(gdf),
            'column_count': len(gdf.columns),
            'setagaya_count': len(setagaya) if setagaya_cols else 0,
            'important_fields': important_fields,
            'columns': list(gdf.columns)
        }
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == '__main__':
    print("=" * 80)
    print("Phase 2: ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®èª¿æŸ»")
    print("=" * 80)
    
    # ä»£è¡¨çš„ãªå¹´åº¦ã‚’èª¿æŸ»
    years_to_check = [2000, 2005, 2010, 2012, 2015, 2016, 2017, 2018, 2020, 2021, 2022, 2025]
    
    results = []
    for year in years_to_check:
        result = investigate_year(year)
        if result:
            results.append(result)
    
    # çµæœã‚’JSONã«ä¿å­˜
    output_file = Path('kokudo_data_structure_investigation.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… èª¿æŸ»çµæœã‚’ä¿å­˜: {output_file}")
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã®è¦ç´„
    print("\n" + "=" * 80)
    print("ğŸ“Š ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°è¦ç´„")
    print("=" * 80)
    
    for result in results:
        year = result['year']
        fields = result['important_fields']
        print(f"\n{year}å¹´:")
        print(f"  å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰: {fields.get('city_code', 'ä¸æ˜')}")
        print(f"  ä½æ‰€:          {fields.get('address', 'ä¸æ˜')}")
        print(f"  ä¾¡æ ¼:          {fields.get('price', 'ä¸æ˜')}")
        print(f"  ã‚«ãƒ©ãƒ æ•°:      {result['column_count']}å€‹")
        print(f"  ä¸–ç”°è°·åŒº:      {result['setagaya_count']}ä»¶")

